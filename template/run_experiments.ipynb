{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 â€“ Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Reload all modules without having to restart the kernel\n",
    "# Useful for development if you have edited any of the external code files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from decision_tree import DecisionTree\n",
    "from random_forest import RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Do data loading, exploration and preprocessing as you see fit.\n",
    "\n",
    "Here is some code to load the dataset to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns names: ['citric_acid', 'residual_sugar', 'pH', 'sulphates', 'alcohol']\n",
      "Target column name: type\n",
      "X shape: (500, 5)\n",
      "y shape: (500,)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"../wine_dataset_small.csv\", delimiter=\",\", dtype=float, names=True)\n",
    "\n",
    "feature_names = list(data.dtype.names[:-1])\n",
    "target_name = data.dtype.names[-1]\n",
    "\n",
    "X = np.array([data[feature] for feature in feature_names]).T\n",
    "y = data[target_name].astype(int)\n",
    "\n",
    "# Create seed\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "print(f\"Feature columns names: {feature_names}\")\n",
    "print(f\"Target column name: {target_name}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and val, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data (use 70% for training and 30% for validation)\n",
    "X_train_and_val, X_test, y_train_and_val, y_test = train_test_split(X, y, test_size=0.3, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Kfold with 5 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Init KFold with 5 splits\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "criterion_values = [\"gini\", \"entropy\"]\n",
    "\n",
    "# Desicion Tree\n",
    "dt_max_depth_values = [3, 5, 8, 10, 12, 15, None]\n",
    "\n",
    "# Random Forest\n",
    "rf_n_estimators_values = [5]\n",
    "rf_max_depth_values = [3, 5, 10, None]\n",
    "rf_max_features_values = [\"sqrt\", \"log2\", None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the self made DecisionTree to get optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(model_class: DecisionTree | DecisionTreeClassifier | RandomForest | RandomForestClassifier, parameter_grid):\n",
    "    # Seed for deterministic output\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_hyperparameters = {}\n",
    "\n",
    "    for params in parameter_grid:\n",
    "        accuracies = []\n",
    "        \n",
    "        # Perform k-fold cross-validation\n",
    "        for train_index, val_index in kf.split(X_train_and_val):\n",
    "            X_train, X_val = X[train_index], X[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "            model = model_class(**params)\n",
    "\n",
    "            # Train the decision tree\n",
    "            if model_class is DecisionTree:\n",
    "                model.root = model.fit(X_train, y_train)\n",
    "            else:\n",
    "                # Train the random forest\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions on the validation fold\n",
    "            y_pred = model.predict(X_val)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            accuracy = accuracy_score(y_val, y_pred)\n",
    "            accuracies.append(accuracy)\n",
    "        \n",
    "        # Calculate the mean accuracy across all folds\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        \n",
    "        if mean_accuracy > best_accuracy:\n",
    "            best_accuracy = mean_accuracy\n",
    "            best_hyperparameters = params\n",
    "    \n",
    "    return best_hyperparameters, best_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Desicion Tree Accuracy (self): 0.7742857142857142\n",
      "Best Desicion Tree Parameters (self): {'max_depth': 5, 'criterion': 'gini'}\n",
      "\n",
      "Best Desicion Tree Accuracy (sklearn): 0.8428571428571429\n",
      "Best Desicion Tree Parameters (sklearn): {'max_depth': 12, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "# Tune Decision Tree\n",
    "dt_param_grid = [{'max_depth': md, 'criterion': c} for md in dt_max_depth_values for c in criterion_values]\n",
    "\n",
    "best_hyperparameters_dt_self, best_accuracy_dt_self = tune_hyperparameters(DecisionTree, dt_param_grid)\n",
    "best_hyperparameters_dt_sklearn, best_accuracy_dt_sklearn = tune_hyperparameters(DecisionTreeClassifier, dt_param_grid)\n",
    "\n",
    "\n",
    "print(f\"Best Desicion Tree Accuracy (self): {best_accuracy_dt_self}\")\n",
    "print(f\"Best Desicion Tree Parameters (self): {best_hyperparameters_dt_self}\")\n",
    "print()\n",
    "print(f\"Best Desicion Tree Accuracy (sklearn): {best_accuracy_dt_sklearn}\")\n",
    "print(f\"Best Desicion Tree Parameters (sklearn): {best_hyperparameters_dt_sklearn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the self made RandomForest to get optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Accuracy (self): 0.8400000000000001\n",
      "Best Random Forest Parameters (self): {'n_estimators': 5, 'max_depth': None, 'max_features': None, 'criterion': 'entropy'}\n",
      "\n",
      "Best Random Forest Accuracy (sklearn): 0.8514285714285714\n",
      "Best Random Forest Parameters (sklearn): {'n_estimators': 5, 'max_depth': None, 'max_features': 'log2', 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "# Tune Random Forest\n",
    "rf_param_grid = [\n",
    "    {'n_estimators': ne, 'max_depth': md, 'max_features': mf, 'criterion': c} \n",
    "    for ne in rf_n_estimators_values \n",
    "    for md in rf_max_depth_values \n",
    "    for mf in rf_max_features_values \n",
    "    for c in criterion_values\n",
    "]\n",
    "\n",
    "best_hyperparameters_rf_self, best_accuracy_rf_self = tune_hyperparameters(RandomForest, rf_param_grid)\n",
    "best_hyperparameters_rf_sklearn, best_accuracy_rf_sklearn = tune_hyperparameters(RandomForestClassifier, rf_param_grid)\n",
    "\n",
    "print(f\"Best Random Forest Accuracy (self): {best_accuracy_rf_self}\")\n",
    "print(f\"Best Random Forest Parameters (self): {best_hyperparameters_rf_self}\")\n",
    "print()\n",
    "print(f\"Best Random Forest Accuracy (sklearn): {best_accuracy_rf_sklearn}\")\n",
    "print(f\"Best Random Forest Parameters (sklearn): {best_hyperparameters_rf_sklearn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Random Forest Accuracy (self): 0.8400000000000001\n",
    "\n",
    "Best Random Forest Parameters (self): {'n_estimators': 5, 'max_depth': None, 'max_features': None, 'criterion': 'entropy'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test the best models\n",
    "def evaluate_model(model_class, params):\n",
    "    model = model_class(**params)\n",
    "    if model_class is DecisionTree:\n",
    "        model.root = model.fit(X_train_and_val, y_train_and_val)\n",
    "    else:\n",
    "        model.fit(X_train_and_val, y_train_and_val)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train RandomForest and DecisionTree to the best hyperparameters, and check the accuracy of the models to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy DT (self): 0.8\n",
      "Test accuracy DT (sklearn): 0.8466666666666667\n",
      "Test accuracy RF (self): 0.84\n",
      "Test accuracy RF (sklearn): 0.9\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy DT (self): {evaluate_model(DecisionTree, best_hyperparameters_dt_self)}\")\n",
    "print(f\"Test accuracy DT (sklearn): {evaluate_model(DecisionTreeClassifier, best_hyperparameters_dt_sklearn)}\")\n",
    "print(f\"Test accuracy RF (self): {evaluate_model(RandomForest, best_hyperparameters_rf_self)}\")\n",
    "print(f\"Test accuracy RF (sklearn): {evaluate_model(RandomForestClassifier, best_hyperparameters_rf_sklearn)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF264",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
