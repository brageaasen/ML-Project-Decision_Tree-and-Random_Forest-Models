{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 â€“ Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Reload all modules without having to restart the kernel\n",
    "# Useful for development if you have edited any of the external code files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Do data loading, exploration and preprocessing as you see fit.\n",
    "\n",
    "Here is some code to load the dataset to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns names: ['citric_acid', 'residual_sugar', 'pH', 'sulphates', 'alcohol']\n",
      "Target column name: type\n",
      "X shape: (500, 5)\n",
      "y shape: (500,)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"../wine_dataset_small.csv\", delimiter=\",\", dtype=float, names=True)\n",
    "\n",
    "feature_names = list(data.dtype.names[:-1])\n",
    "target_name = data.dtype.names[-1]\n",
    "\n",
    "X = np.array([data[feature] for feature in feature_names]).T\n",
    "y = data[target_name].astype(int)\n",
    "\n",
    "print(f\"Feature columns names: {feature_names}\")\n",
    "print(f\"Target column name: {target_name}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and val, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data (use 70% for training and 30% for validation)\n",
    "X_train_and_val, X_test, y_train_and_val, y_test = train_test_split(X, y, test_size=0.3, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Kfold with 5 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Init KFold with 5 splits\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the self made DecisionTree to get optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.7742857142857142\n",
      "Best Parameters: {'max_depth': 5, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "from decision_tree import DecisionTree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Hyperparameter grid\n",
    "max_depth_values = [3, 5, 8, 10, 12, 15, None]\n",
    "criterion_values = [\"gini\", \"entropy\"]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters_dt = {}\n",
    "\n",
    "# Loop through different hyperparameter combinations\n",
    "for max_depth in max_depth_values:\n",
    "    for criterion in criterion_values:\n",
    "        accuracies = []\n",
    "        \n",
    "        # Perform k-fold cross-validation\n",
    "        for train_index, val_index in kf.split(X_train_and_val):\n",
    "            X_train, X_val = X[train_index], X[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "            \n",
    "            # Train the decision tree\n",
    "            dt = DecisionTree(max_depth=max_depth, criterion=criterion)\n",
    "            dt.root = dt.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions on the validation fold\n",
    "            y_pred = dt.predict(X_val)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            accuracy = accuracy_score(y_val, y_pred)\n",
    "            accuracies.append(accuracy)\n",
    "        \n",
    "        # Calculate the mean accuracy across all folds\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        \n",
    "        if mean_accuracy > best_accuracy:\n",
    "            best_accuracy = mean_accuracy\n",
    "            best_hyperparameters_dt = {\"max_depth\": max_depth, \"criterion\": criterion}\n",
    "\n",
    "print(f\"Best Accuracy: {best_accuracy}\")\n",
    "print(f\"Best Parameters: {best_hyperparameters_dt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the self made RandomForest to get optimal hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters to consider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest hyperparameters\n",
    "n_estimators_values = [5, 10]\n",
    "max_depth_values = [3, 5, 10, 15, 20, 30, None]\n",
    "max_features_values = [\"sqrt\", \"log2\", None]\n",
    "criterion_values = [\"gini\", \"entropy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Accuracy: 0.86\n",
      "Best Random Forest Parameters: {'n_estimators': 10, 'max_depth': 5, 'max_features': 'log2', 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "from random_forest import RandomForest\n",
    "\n",
    "def tune_random_forest_hyperparameters(n_estimators_values, max_depth_values, max_features_values, criterion_values):\n",
    "    best_accuracy_rf = 0\n",
    "    best_hyperparameters_rf = {}\n",
    "\n",
    "    # Loop through hyperparameter combinations\n",
    "    for n_estimators in n_estimators_values:\n",
    "        for max_depth in max_depth_values:\n",
    "            for max_features in max_features_values:\n",
    "                for criterion in criterion_values:  # Iterate over criterion\n",
    "                    accuracies = []\n",
    "                    \n",
    "                    # Perform the k-fold cross-validation\n",
    "                    for train_index, val_index in kf.split(X_train_and_val):\n",
    "                        X_train, X_val = X[train_index], X[val_index]\n",
    "                        y_train, y_val = y[train_index], y[val_index]\n",
    "                        \n",
    "                        # Train the random forest\n",
    "                        rf = RandomForest(\n",
    "                            n_estimators=n_estimators, max_depth=max_depth, max_features=max_features, criterion=criterion\n",
    "                        )\n",
    "                        rf.fit(X_train, y_train)\n",
    "                        \n",
    "                        # Make predictions on the validation fold\n",
    "                        y_pred = rf.predict(X_val)\n",
    "                        \n",
    "                        # Compute accuracy\n",
    "                        accuracy = accuracy_score(y_val, y_pred)\n",
    "                        accuracies.append(accuracy)\n",
    "                    \n",
    "                    # Calculate the mean accuracy across all folds\n",
    "                    mean_accuracy_rf = np.mean(accuracies)\n",
    "                    \n",
    "                    if mean_accuracy_rf > best_accuracy_rf:\n",
    "                        best_accuracy_rf = mean_accuracy_rf\n",
    "                        # Track the best hyperparameters\n",
    "                        best_hyperparameters = {\n",
    "                            \"n_estimators\": n_estimators,\n",
    "                            \"max_depth\": max_depth,\n",
    "                            \"max_features\": max_features,\n",
    "                            \"criterion\": criterion,\n",
    "                        }\n",
    "    return best_hyperparameters\n",
    "\n",
    "best_hyperparameters_rf = tune_random_forest_hyperparameters(n_estimators_values, max_depth_values, max_features_values, criterion_values)\n",
    "print(f\"Best Random Forest Accuracy: {best_accuracy_rf}\")\n",
    "print(f\"Best Random Forest Parameters: {best_hyperparameters_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "Best Random Forest Accuracy: 0.884\n",
    "Best Random Forest Parameters: {'n_estimators': 25, 'max_depth': 15, 'max_features': 'log2', 'criterion': 'gini'}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train RandomForest and DecisionTree to the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree(\n",
    "    max_depth=best_hyperparameters_dt['max_depth'],\n",
    "    criterion=best_hyperparameters_dt['criterion'],\n",
    ")\n",
    "dt.root = dt.fit(X_train_and_val, y_train_and_val)\n",
    "\n",
    "rf = RandomForest(\n",
    "    n_estimators=best_hyperparameters_rf['n_estimators'],\n",
    "    max_depth=best_hyperparameters_rf['max_depth'],\n",
    "    max_features=best_hyperparameters_rf['max_features'],\n",
    "    criterion=best_hyperparameters_rf['criterion'],\n",
    ")\n",
    "rf.fit(X_train_and_val, y_train_and_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the accuracy of the models to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy RF: 0.8733333333333333\n",
      "Test set accuracy DT: 0.8\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Test set accuracy RF: {accuracy}\")\n",
    "\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Test set accuracy DT: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the sklearn DecisionTreeClassifier and RandomForestClassifier to compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF264",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
